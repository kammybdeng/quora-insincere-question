{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Dense, Input, LSTM, CuDNNLSTM, Embedding, CuDNNGRU, MaxPool2D, Conv2D, Concatenate, SpatialDropout1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Reshape, Flatten, Dropout, Activation\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "b6a8143097bdc17dd844359ba593ef5f72520877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.csv', 'train.csv', 'sample_submission.csv', 'embeddings']\n",
      "['wiki-news-300d-1M', 'glove.840B.300d', 'paragram_300_sl999', 'GoogleNews-vectors-negative300']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input/\"))\n",
    "print(os.listdir(\"../input/embeddings/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "acf649f511d1ac58ee2d3d849cfa3a565b703aa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_original shape :  (1306122, 3)\n",
      "test_original shape :  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "print(\"train_original shape : \",train.shape)\n",
    "print(\"test_original shape : \",test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  ...   target\n",
       "0  00002165364db923c7e6  ...        0\n",
       "1  000032939017120e6e44  ...        0\n",
       "2  0000412ca6e4628ce2cf  ...        0\n",
       "3  000042bf85aa498cd78e  ...        0\n",
       "4  0000455dfa3e01eae3af  ...        0\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_punct = list(string.punctuation)\n",
    "extra_punct = [\n",
    "        ',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&',\n",
    "        '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
    "        '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n",
    "        '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n",
    "        '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n",
    "        '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n",
    "        '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
    "        'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
    "        '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
    "        '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']\n",
    "\n",
    "all_punct = list(set(regular_punct + extra_punct))\n",
    "\n",
    "\n",
    "def spacing_punctuation(text):\n",
    "    \"\"\"\n",
    "    add space before and after punctuation and symbols\n",
    "    \"\"\"\n",
    "    for punc in all_punct:\n",
    "        if punc in text:            \n",
    "            text = text.replace(punc, f\" {punc} \")\n",
    "            \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    preprocess text main steps\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = spacing_punctuation(text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "978a94c1e4cfca3d1de836bbdb196eecb91e6f48"
   },
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 150000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 75 # max number of words in a question to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:10<00:00, 119691.92it/s]\n",
      "100%|██████████| 375806/375806 [00:03<00:00, 118994.02it/s]\n"
     ]
    }
   ],
   "source": [
    "## preprocess\n",
    "train['question_text'] = train['question_text'].progress_apply(preprocess)\n",
    "test['question_text'] = test['question_text'].progress_apply(preprocess)\n",
    "\n",
    "## split to train and val\n",
    "train_df, val_df = train_test_split(train, test_size=0.05, random_state=42)\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_df[\"question_text\"].fillna(\"_##_\").values\n",
    "val_X = val_df[\"question_text\"].fillna(\"_##_\").values\n",
    "test_X = test[\"question_text\"].fillna(\"_##_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "## Get the target values\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values  \n",
    "    \n",
    "#shuffling the data\n",
    "np.random.seed(42)\n",
    "trn_idx = np.random.permutation(len(train_X))\n",
    "val_idx = np.random.permutation(len(val_X))\n",
    "\n",
    "train_X = train_X[trn_idx]\n",
    "val_X = val_X[val_idx]\n",
    "train_y = train_y[trn_idx]\n",
    "val_y = val_y[val_idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/shujian/single-rnn-with-5-folds-snapshot-ensemble\n",
    "def lstm_model():\n",
    "    input_layer = Input(shape=(maxlen,))\n",
    "    # create embedding layer\n",
    "    x = Embedding(max_features, embed_size)(input_layer)\n",
    "    # bidirectional lstm\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    x = Bidirectional(CuDNNLSTM(64, return_sequences=True), name='bidirectional_lstm')(x)\n",
    "    # global_max_pooling1d\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(32, activation=\"relu\", name = 'dense_1')(x)\n",
    "    x = Dense(16, activation=\"relu\", name = 'dense_2')(x)\n",
    "    # output layer\n",
    "    output_layer = Dense(1, activation=\"sigmoid\", name = 'output')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/strideradu/word2vec-and-gensim-go-go-go\n",
    "\n",
    "def train_pred(model, epochs=2):\n",
    "    for e in range(epochs):\n",
    "        model.fit(train_X, train_y, batch_size=512, epochs=1, validation_data=(val_X, val_y))\n",
    "        pred_val_y = model.predict([val_X], batch_size=1024, verbose=0)\n",
    "    pred_test_y = model.predict([test_X], batch_size=1024, verbose=0)\n",
    "    \n",
    "    \n",
    "    # Plot training & validation accuracy values\n",
    "#     plt.plot(model.history['acc'])\n",
    "#     plt.plot(model.history['val_acc'])\n",
    "#     plt.title('Model accuracy')\n",
    "#     plt.ylabel('Accuracy')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Test'], loc='upper left')\n",
    "#     plt.show()\n",
    "\n",
    "#     # Plot training & validation loss values\n",
    "#     plt.plot(model.history.history['loss'])\n",
    "#     plt.plot(model.history.history['val_loss'])\n",
    "#     plt.title('Model loss')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.legend(['Train', 'Test'], loc='upper left')\n",
    "#     plt.show()\n",
    "    return pred_val_y, pred_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 103s 83us/step - loss: 0.1209 - acc: 0.9534 - val_loss: 0.1039 - val_acc: 0.9579\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 98s 79us/step - loss: 0.0958 - acc: 0.9613 - val_loss: 0.1033 - val_acc: 0.9587\n"
     ]
    }
   ],
   "source": [
    "pred_val_y, pred_test_y = train_pred(lstm_model(), epochs = 2) # GloVe only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "outputs.append([pred_val_y, pred_test_y, 'LSTM baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.5964787479992887\n",
      "F1 score at threshold 0.11 is 0.6046087986155387\n",
      "F1 score at threshold 0.12 is 0.6112610516519311\n",
      "F1 score at threshold 0.13 is 0.6177642816473715\n",
      "F1 score at threshold 0.14 is 0.6231729745426388\n",
      "F1 score at threshold 0.15 is 0.6269567785763512\n",
      "F1 score at threshold 0.16 is 0.6316\n",
      "F1 score at threshold 0.17 is 0.6345684039087948\n",
      "F1 score at threshold 0.18 is 0.6384472434441462\n",
      "F1 score at threshold 0.19 is 0.6412165705296277\n",
      "F1 score at threshold 0.2 is 0.6432150090608678\n",
      "F1 score at threshold 0.21 is 0.6439762290653701\n",
      "F1 score at threshold 0.22 is 0.6446317171938273\n",
      "F1 score at threshold 0.23 is 0.6444690265486726\n",
      "F1 score at threshold 0.24 is 0.6448796866256296\n",
      "F1 score at threshold 0.25 is 0.6475048093244314\n",
      "F1 score at threshold 0.26 is 0.6488776912505727\n",
      "F1 score at threshold 0.27 is 0.6483605607693199\n",
      "F1 score at threshold 0.28 is 0.6479962502929459\n",
      "F1 score at threshold 0.29 is 0.6493783303730017\n",
      "F1 score at threshold 0.3 is 0.6478636581853097\n",
      "F1 score at threshold 0.31 is 0.6488521802502125\n",
      "F1 score at threshold 0.32 is 0.6493921159277907\n",
      "F1 score at threshold 0.33 is 0.6460736881280239\n",
      "F1 score at threshold 0.34 is 0.644918444165621\n",
      "F1 score at threshold 0.35 is 0.6434010152284264\n",
      "F1 score at threshold 0.36 is 0.6427289048473969\n",
      "F1 score at threshold 0.37 is 0.63918060417477\n",
      "F1 score at threshold 0.38 is 0.638565257232622\n",
      "F1 score at threshold 0.39 is 0.6370487901626338\n",
      "F1 score at threshold 0.4 is 0.6339118825100134\n",
      "F1 score at threshold 0.41 is 0.6326420684082952\n",
      "F1 score at threshold 0.42 is 0.6288982704616642\n",
      "F1 score at threshold 0.43 is 0.6264794935315167\n",
      "F1 score at threshold 0.44 is 0.6237665045170258\n",
      "F1 score at threshold 0.45 is 0.6197499648827083\n",
      "F1 score at threshold 0.46 is 0.6152535151256925\n",
      "F1 score at threshold 0.47 is 0.612051649928264\n",
      "F1 score at threshold 0.48 is 0.6071583828430662\n",
      "F1 score at threshold 0.49 is 0.6038287300891422\n",
      "F1 score at threshold 0.5 is 0.6012124796687861\n",
      "Best threshold:  0.32\n"
     ]
    }
   ],
   "source": [
    "thresholds = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    res = metrics.f1_score(val_y, (pred_val_y > thresh).astype(int))\n",
    "    thresholds.append([thresh, res])\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "best_thresh = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = (pred_test_y > best_thresh).astype(int)\n",
    "test_df = pd.read_csv(\"../input/test.csv\", usecols=[\"qid\"])\n",
    "out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "out_df['prediction'] = pred_test_y\n",
    "out_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
