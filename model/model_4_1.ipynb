{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Dense, Input, LSTM, CuDNNLSTM, Embedding, CuDNNGRU, MaxPool2D, Conv2D, Concatenate, SpatialDropout1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers import Reshape, Flatten, Dropout, Activation\n",
    "from keras.layers import Activation, Wrapper\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape :  (1306122, 3)\n",
      "test shape :  (375806, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "print(\"train shape : \", train.shape)\n",
    "print(\"test shape : \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid  ...   target\n",
       "0  00002165364db923c7e6  ...        0\n",
       "1  000032939017120e6e44  ...        0\n",
       "2  0000412ca6e4628ce2cf  ...        0\n",
       "3  000042bf85aa498cd78e  ...        0\n",
       "4  0000455dfa3e01eae3af  ...        0\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_embedding(filepath):\n",
    "    \"\"\"\n",
    "    Given a filepath to embeddings file, return a word to vec dictionary, \n",
    "    in other words, word_embedding\n",
    "    Ex. {'word': array([1.97, -0.63, ..., 0.573, 2.54])}\n",
    "    \"\"\"\n",
    "    def _get_vec(word, *arr):\n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "    print('load word embedding ......')\n",
    "    \n",
    "    try:\n",
    "        word_embedding = dict(_get_vec(*w.split(' ')) for w in open(filepath))\n",
    "    except UnicodeDecodeError:\n",
    "        word_embedding = dict(_get_vec(*w.split(' ')) for w in open(filepath, encoding=\"utf8\", errors='ignore'))\n",
    "    \n",
    "    # sanity check for word vectors must with lengths of 300\n",
    "    words_to_del = []\n",
    "    for word, vec in word_embedding.items():\n",
    "        if len(vec) != 300:\n",
    "            words_to_del.append(word)\n",
    "    for word in words_to_del:\n",
    "        del word_embedding[word]\n",
    "    return word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load word embedding ......\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_FILE_glove = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "embeddings_index_glove = load_word_embedding(EMBEDDING_FILE_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "regular_punct = list(string.punctuation)\n",
    "extra_punct = [\n",
    "        ',', '.', '\"', ':', ')', '(', '!', '?', '|', ';', \"'\", '$', '&',\n",
    "        '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£',\n",
    "        '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',\n",
    "        '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', '“', '★', '”',\n",
    "        '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾',\n",
    "        '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', '▒', '：', '¼', '⊕', '▼',\n",
    "        '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲',\n",
    "        'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', '∙', '）', '↓', '、', '│', '（', '»',\n",
    "        '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø',\n",
    "        '¹', '≤', '‡', '√', '«', '»', '´', 'º', '¾', '¡', '§', '£', '₤']\n",
    "\n",
    "all_punct = list(set(regular_punct + extra_punct))\n",
    "\n",
    "def spacing_punctuation(text):\n",
    "    \"\"\"\n",
    "    add space before and after punctuation and symbols\n",
    "    \"\"\"\n",
    "    for punc in all_punct:\n",
    "        if punc in text:            \n",
    "            text = text.replace(punc, f\" {punc} \")\n",
    "            \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_misspell(text):\n",
    "    \"\"\"\n",
    "    misspell list (quora vs. glove)\n",
    "    \"\"\"\n",
    "    \n",
    "    mispell_dict = {'demonitisation': 'demonetization', 'demonitization': 'demonetization', \n",
    "                    'demonetisation': 'demonetization',\n",
    "                    'pokémon': 'pokemon',\n",
    "                    'Wjy': 'Why',\n",
    "                    'Whst' : 'What',\n",
    "                    'BNBR': 'Be Nice Be Respectful',\n",
    "                    'Bolsonaro': 'Jair Bolsonaro',\n",
    "                    'XXXTentacion': 'Tentacion',\n",
    "                    'Žižek': 'Slovenian philosopher Slavoj Žižek',\n",
    "                    'Adityanath': 'Indian monk Yogi Adityanath',\n",
    "                    'Brexit': 'British Exit',\n",
    "                    'Brexiter': 'British Exit supporter',\n",
    "                    'Brexiters': 'British Exit supporters',\n",
    "                    'Brexiteer': 'British Exit supporter',\n",
    "                    'Brexiteers': 'British Exit supporters',\n",
    "                    'Brexiting': 'British Exit',\n",
    "                    'Brexitosis': 'British Exit disorder',\n",
    "                    'brexit': 'British Exit',\n",
    "                    'brexiters': 'British Exit supporters',\n",
    "                    'cryptocurrencies': 'cryptocurrency',\n",
    "                    'Cryptocurrency': 'cryptocurrency',\n",
    "                    'Litecoin' : 'cryptocurrency',\n",
    "                    'litecoin' : 'cryptocurrency',\n",
    "                    'altcoin' : 'cryptocurrency',\n",
    "                    'altcoins' : 'cryptocurrency',\n",
    "                    'jallikattu': 'Jallikattu',\n",
    "                    'Swachh': 'Swachh Bharat mission campaign ',\n",
    "                    'SJWs': 'social justice warrior',\n",
    "                    'Quorans': 'Quoran',\n",
    "                    'Qoura': 'Quora',\n",
    "                    'quoras': 'Quora',\n",
    "                    'Quroa': 'Quora',\n",
    "                    'QUORA': 'Quora',\n",
    "                    'Qoura': 'Quora',\n",
    "                    'narcissit': 'narcissist',\n",
    "                    'ethereum': 'Ethereum',\n",
    "                    'Blockchain': 'blockchain',\n",
    "                    'UCEED': 'Undergraduate Common Entrance Examination for Design',\n",
    "                    'GDPR': 'General Data Protection Regulation',\n",
    "                    'Redmi' : 'Xiaomi smartphone',\n",
    "                    'OnePlus': 'Android smartphone',\n",
    "                    'Machedo' : 'hot guy',\n",
    "                    'Coinbase':'bitcoin broker',\n",
    "                    'coinbase':'bitcoin broker',\n",
    "                    'DCEU' : 'American media franchise',\n",
    "                    'IIEST': 'Indian Institutes of Engineering Science and Technology',\n",
    "                    'Upwork' : 'global freelancing platform',\n",
    "                    'upwork' : 'global freelancing platform',\n",
    "                    'HackerRank' : 'technology company focuses on competitive programming challenges',\n",
    "                    'pokémon': 'pokemon'}\n",
    "\n",
    "    misspell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "\n",
    "    def _replace(match):\n",
    "        \"\"\"\n",
    "        reference: https://www.kaggle.com/hengzheng/attention-capsule-why-not-both-lb-0-694 # noqa\n",
    "        \"\"\"\n",
    "        try:\n",
    "            word = mispell_dict.get(match.group(0))\n",
    "        except KeyError:\n",
    "            word = match.group(0)\n",
    "            print('!!Error: Could Not Find Key: {}'.format(word))\n",
    "        return word\n",
    "    return misspell_re.sub(_replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"\n",
    "    preprocess text main steps\n",
    "\n",
    "    \"\"\"\n",
    "    text = spacing_punctuation(text)\n",
    "    text = clean_misspell(text)\n",
    "   \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 150000 # 150k to 180k how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 75 # max number of words in a question to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenize text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [00:25<00:00, 50824.33it/s]\n",
      "100%|██████████| 375806/375806 [00:07<00:00, 51636.13it/s]\n"
     ]
    }
   ],
   "source": [
    "## preprocess\n",
    "train['question_text'] = train['question_text'].progress_apply(preprocess)\n",
    "test['question_text'] = test['question_text'].progress_apply(preprocess)\n",
    "\n",
    "## split to train and val\n",
    "train_df, val_df = train_test_split(train, test_size=0.05, random_state=42)\n",
    "\n",
    "## fill up the missing values\n",
    "train_X = train_df[\"question_text\"].fillna(\"_##_\").values\n",
    "val_X = val_df[\"question_text\"].fillna(\"_##_\").values\n",
    "test_X = test[\"question_text\"].fillna(\"_##_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features) # glove\n",
    "\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "val_X = pad_sequences(val_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "train_y = train_df['target'].values\n",
    "val_y = val_df['target'].values  \n",
    "\n",
    "#shuffling the data\n",
    "np.random.seed(42)\n",
    "trn_idx = np.random.permutation(len(train_X))\n",
    "val_idx = np.random.permutation(len(val_X))\n",
    "\n",
    "train_X = train_X[trn_idx]\n",
    "val_X = val_X[val_idx]\n",
    "train_y = train_y[trn_idx]\n",
    "val_y = val_y[val_idx] \n",
    "\n",
    "## word index dictionary from input text/document\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding_weights(word_index, embeddings_index, max_features):\n",
    "    '''\n",
    "    input: word_index from training set and embedding from embedding file\n",
    "    output: matrix with matched embedding arrays\n",
    "    '''\n",
    "    \n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    \n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    \n",
    "    # matching the word and updating the corresponding embedding vector  \n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = create_embedding_weights(word_index, embeddings_index_glove, max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(embedding_matrix):\n",
    "    \n",
    "    input_layer = Input(shape=(maxlen,))\n",
    "    # create embedding layer\n",
    "    x = Embedding(max_features, embed_size, weights = [embedding_matrix])(input_layer)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    # bidirectional lstm\n",
    "    x1 = Bidirectional(CuDNNLSTM(128, return_sequences=True), name='bidirectional_lstm')(x)\n",
    "    # bidirectional gru\n",
    "    x2 = Bidirectional(CuDNNGRU(128, return_sequences=True), name='bidirectional_gru')(x1)\n",
    "    # attention\n",
    "    #atten = Attention(step_dim=maxlen)(x)\n",
    "    # global_max_pooling1d\n",
    "\n",
    "    max_pool1 = GlobalMaxPooling1D()(x1)\n",
    "    max_pool2 = GlobalMaxPooling1D()(x2)\n",
    "    x = Concatenate()([max_pool1, max_pool2])\n",
    "    #x = Dense(32, activation=\"relu\", name = 'dense_1')(x)\n",
    "    #x = Dense(16, activation=\"relu\", name = 'dense_2')(x)\n",
    "    # output layer\n",
    "    output_layer = Dense(1, activation=\"sigmoid\", name = 'output')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model_2(embedding_matrix):\n",
    "    \n",
    "    input_layer = Input(shape=(maxlen,))\n",
    "    # create embedding layer\n",
    "    x = Embedding(max_features, embed_size, weights = [embedding_matrix])(input_layer)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    # bidirectional lstm\n",
    "    x1 = Bidirectional(CuDNNLSTM(256, return_sequences=True), name='bidirectional_lstm')(x)\n",
    "    # bidirectional gru\n",
    "    x2 = Bidirectional(CuDNNGRU(128, return_sequences=True), name='bidirectional_gru')(x1)\n",
    "    # attention\n",
    "    #atten = Attention(step_dim=maxlen)(x)\n",
    "    # global_max_pooling1d\n",
    "\n",
    "    max_pool1 = GlobalMaxPooling1D()(x1)\n",
    "    max_pool2 = GlobalMaxPooling1D()(x2)\n",
    "    x = Concatenate()([max_pool1, max_pool2])\n",
    "    #x = Dense(32, activation=\"relu\", name = 'dense_1')(x)\n",
    "    #x = Dense(16, activation=\"relu\", name = 'dense_2')(x)\n",
    "    # output layer\n",
    "    output_layer = Dense(1, activation=\"sigmoid\", name = 'output')(x)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model_3(embedding_matrix):\n",
    "    \n",
    "    input_layer = Input(shape=(maxlen,))\n",
    "    # create embedding layer\n",
    "    x = Embedding(max_features, embed_size, weights = [embedding_matrix])(input_layer)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    # bidirectional lstm\n",
    "    x1 = Bidirectional(CuDNNLSTM(256, return_sequences=True), name='bidirectional_lstm')(x)\n",
    "    # bidirectional gru\n",
    "    x2 = Bidirectional(CuDNNGRU(128, return_sequences=True), name='bidirectional_gru')(x1)\n",
    "    # attention\n",
    "    atten = Attention(step_dim=maxlen)(x)\n",
    "    # global_max_pooling1d\n",
    "\n",
    "    max_pool1 = GlobalMaxPooling1D()(x1)\n",
    "    max_pool2 = GlobalMaxPooling1D()(x2)\n",
    "    conc = Concatenate()([max_pool1, max_pool2])\n",
    "    conc = Dense(16, activation=\"relu\", name = 'dense_1')(conc)\n",
    "    out = Concatenate(axis=-1)([atten, conc])\n",
    "    \n",
    "    #x = Dense(32, activation=\"relu\", name = 'dense_1')(x)\n",
    "    #x = Dense(16, activation=\"relu\", name = 'dense_2')(x)\n",
    "    # output layer\n",
    "    output_layer = Dense(1, activation=\"sigmoid\", name = 'output')(out)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model_4(embedding_matrix):\n",
    "    \n",
    "    input_layer = Input(shape=(maxlen,))\n",
    "    # create embedding layer\n",
    "    x = Embedding(max_features, embed_size, weights = [embedding_matrix])(input_layer)\n",
    "    x = SpatialDropout1D(0.2)(x)\n",
    "    # bidirectional lstm\n",
    "    x1 = Bidirectional(CuDNNLSTM(256, return_sequences=True), name='bidirectional_lstm')(x)\n",
    "    # bidirectional gru\n",
    "    x2 = Bidirectional(CuDNNGRU(128, return_sequences=True), name='bidirectional_gru')(x1)\n",
    "    # attention\n",
    "    atten = Attention(step_dim=maxlen)(x2)\n",
    "    # global_max_pooling1d\n",
    "\n",
    "    max_pool1 = GlobalMaxPooling1D()(x1)\n",
    "    max_pool2 = GlobalMaxPooling1D()(x2)\n",
    "    conc = Concatenate()([max_pool1, max_pool2])\n",
    "    conc = Dense(8, activation=\"relu\", name = 'dense_1')(conc)\n",
    "    out = Concatenate(axis=-1)([atten, conc])\n",
    "    \n",
    "    #x = Dense(32, activation=\"relu\", name = 'dense_1')(x)\n",
    "    #x = Dense(16, activation=\"relu\", name = 'dense_2')(x)\n",
    "    # output layer\n",
    "    output_layer = Dense(1, activation=\"sigmoid\", name = 'output')(out)\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/suicaokhoailang/lstm-attention-baseline-0-652-lb\n",
    "\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "        \n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/strideradu/word2vec-and-gensim-go-go-go\n",
    "\n",
    "def train_pred(model, epochs=2):\n",
    "    for e in range(epochs):\n",
    "        model.fit(train_X, train_y, batch_size=512, epochs=1, validation_data=(val_X, val_y))\n",
    "        pred_val_y = model.predict([val_X], batch_size=1024, verbose=0)\n",
    "    pred_test_y = model.predict([test_X], batch_size=1024, verbose=0)\n",
    "    return pred_val_y, pred_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = lstm_model(embedding_matrix)\n",
    "#F1 score at threshold 0.36 is 0.685829670982302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 199s 160us/step - loss: 0.1098 - acc: 0.9564 - val_loss: 0.0957 - val_acc: 0.9611\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 195s 157us/step - loss: 0.0912 - acc: 0.9633 - val_loss: 0.0942 - val_acc: 0.9616\n"
     ]
    }
   ],
   "source": [
    "pred_val_y, pred_test_y = train_pred(model, epochs=2) # GloVe only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.5966323196783111\n",
      "F1 score at threshold 0.11 is 0.6056145155768572\n",
      "F1 score at threshold 0.12 is 0.6125152518738017\n",
      "F1 score at threshold 0.13 is 0.6177017808097812\n",
      "F1 score at threshold 0.14 is 0.624165915238954\n",
      "F1 score at threshold 0.15 is 0.6298332417078981\n",
      "F1 score at threshold 0.16 is 0.6349353909082458\n",
      "F1 score at threshold 0.17 is 0.6383460775984141\n",
      "F1 score at threshold 0.18 is 0.6433767228177641\n",
      "F1 score at threshold 0.19 is 0.6470303265187483\n",
      "F1 score at threshold 0.2 is 0.6520585634273361\n",
      "F1 score at threshold 0.21 is 0.6561225504824431\n",
      "F1 score at threshold 0.22 is 0.6586272736408401\n",
      "F1 score at threshold 0.23 is 0.6608536956301329\n",
      "F1 score at threshold 0.24 is 0.6635963565653464\n",
      "F1 score at threshold 0.25 is 0.6647380927781796\n",
      "F1 score at threshold 0.26 is 0.6676415291414247\n",
      "F1 score at threshold 0.27 is 0.6695514511873351\n",
      "F1 score at threshold 0.28 is 0.6714255273812061\n",
      "F1 score at threshold 0.29 is 0.6743311485978296\n",
      "F1 score at threshold 0.3 is 0.6748506246605105\n",
      "F1 score at threshold 0.31 is 0.6765318425956375\n",
      "F1 score at threshold 0.32 is 0.6775157754898704\n",
      "F1 score at threshold 0.33 is 0.677610273590173\n",
      "F1 score at threshold 0.34 is 0.6798062844914968\n",
      "F1 score at threshold 0.35 is 0.6818749290659403\n",
      "F1 score at threshold 0.36 is 0.6818912095478539\n",
      "F1 score at threshold 0.37 is 0.6829324699352451\n",
      "F1 score at threshold 0.38 is 0.6840018656716419\n",
      "F1 score at threshold 0.39 is 0.6847736625514402\n",
      "F1 score at threshold 0.4 is 0.6866167913549459\n",
      "F1 score at threshold 0.41 is 0.6864103176498686\n",
      "F1 score at threshold 0.42 is 0.6853973230435306\n",
      "F1 score at threshold 0.43 is 0.6849981749604573\n",
      "F1 score at threshold 0.44 is 0.6834479371316305\n",
      "F1 score at threshold 0.45 is 0.6812887236679059\n",
      "F1 score at threshold 0.46 is 0.6814314314314315\n",
      "F1 score at threshold 0.47 is 0.679364278506559\n",
      "F1 score at threshold 0.48 is 0.6777070063694268\n",
      "F1 score at threshold 0.49 is 0.675070748649344\n",
      "F1 score at threshold 0.5 is 0.6743702934302779\n",
      "Best threshold:  0.4\n"
     ]
    }
   ],
   "source": [
    "thresholds = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    res = metrics.f1_score(val_y, (pred_val_y > thresh).astype(int))\n",
    "    thresholds.append([thresh, res])\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "best_thresh = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = lstm_model_2(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 287s 232us/step - loss: 0.1087 - acc: 0.9569 - val_loss: 0.0952 - val_acc: 0.9615\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 284s 229us/step - loss: 0.0905 - acc: 0.9635 - val_loss: 0.0939 - val_acc: 0.9621\n"
     ]
    }
   ],
   "source": [
    "#del model\n",
    "pred_val_y_2, pred_test_y_2 = train_pred(model_2, epochs=2) # GloVe only\n",
    "\n",
    "#F1 score at threshold 0.45 is 0.6864916927522274"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.6266823231867039\n",
      "F1 score at threshold 0.11 is 0.633940062511491\n",
      "F1 score at threshold 0.12 is 0.6395435839880285\n",
      "F1 score at threshold 0.13 is 0.6444190910819547\n",
      "F1 score at threshold 0.14 is 0.650357764455618\n",
      "F1 score at threshold 0.15 is 0.653412985995495\n",
      "F1 score at threshold 0.16 is 0.6585754078790291\n",
      "F1 score at threshold 0.17 is 0.6606909054285426\n",
      "F1 score at threshold 0.18 is 0.6631342979417157\n",
      "F1 score at threshold 0.19 is 0.6655005659018418\n",
      "F1 score at threshold 0.2 is 0.668538741549662\n",
      "F1 score at threshold 0.21 is 0.669049621530698\n",
      "F1 score at threshold 0.22 is 0.6715514495062122\n",
      "F1 score at threshold 0.23 is 0.673029490616622\n",
      "F1 score at threshold 0.24 is 0.675259965337955\n",
      "F1 score at threshold 0.25 is 0.6779921087242438\n",
      "F1 score at threshold 0.26 is 0.6792118662829312\n",
      "F1 score at threshold 0.27 is 0.6778336125069794\n",
      "F1 score at threshold 0.28 is 0.678462752169503\n",
      "F1 score at threshold 0.29 is 0.6781321184510252\n",
      "F1 score at threshold 0.3 is 0.6797565736594328\n",
      "F1 score at threshold 0.31 is 0.6812064965197215\n",
      "F1 score at threshold 0.32 is 0.6828868873552462\n",
      "F1 score at threshold 0.33 is 0.6843657817109144\n",
      "F1 score at threshold 0.34 is 0.6842983083154633\n",
      "F1 score at threshold 0.35 is 0.684944684944685\n",
      "F1 score at threshold 0.36 is 0.6851806936696581\n",
      "F1 score at threshold 0.37 is 0.6842684268426842\n",
      "F1 score at threshold 0.38 is 0.6831976313841599\n",
      "F1 score at threshold 0.39 is 0.6820104503607862\n",
      "F1 score at threshold 0.4 is 0.6815907953976988\n",
      "F1 score at threshold 0.41 is 0.6812854442344045\n",
      "F1 score at threshold 0.42 is 0.6813912160446814\n",
      "F1 score at threshold 0.43 is 0.6804097311139564\n",
      "F1 score at threshold 0.44 is 0.6783731439638476\n",
      "F1 score at threshold 0.45 is 0.6764591186793188\n",
      "F1 score at threshold 0.46 is 0.6721719753571898\n",
      "F1 score at threshold 0.47 is 0.6696629213483146\n",
      "F1 score at threshold 0.48 is 0.6664889362836577\n",
      "F1 score at threshold 0.49 is 0.6648757555406313\n",
      "F1 score at threshold 0.5 is 0.6641366223908919\n",
      "Best threshold:  0.36\n"
     ]
    }
   ],
   "source": [
    "thresholds = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    res = metrics.f1_score(val_y, (pred_val_y_2 > thresh).astype(int))\n",
    "    thresholds.append([thresh, res])\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "best_thresh = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = lstm_model_3(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 295s 238us/step - loss: 0.1104 - acc: 0.9564 - val_loss: 0.0963 - val_acc: 0.9605\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 291s 235us/step - loss: 0.0907 - acc: 0.9634 - val_loss: 0.0949 - val_acc: 0.9615\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 292s 235us/step - loss: 0.0780 - acc: 0.9687 - val_loss: 0.0968 - val_acc: 0.9612\n"
     ]
    }
   ],
   "source": [
    "pred_val_y_3, pred_test_y_3 = train_pred(model_3, epochs=3) # GloVe only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.6219468390804598\n",
      "F1 score at threshold 0.11 is 0.6283307389433201\n",
      "F1 score at threshold 0.12 is 0.6342506507995538\n",
      "F1 score at threshold 0.13 is 0.6391830559757942\n",
      "F1 score at threshold 0.14 is 0.6408045977011494\n",
      "F1 score at threshold 0.15 is 0.6451800796039219\n",
      "F1 score at threshold 0.16 is 0.6481317164546978\n",
      "F1 score at threshold 0.17 is 0.6501844282723557\n",
      "F1 score at threshold 0.18 is 0.6527483610690872\n",
      "F1 score at threshold 0.19 is 0.6555238483489604\n",
      "F1 score at threshold 0.2 is 0.657457994021235\n",
      "F1 score at threshold 0.21 is 0.6604147129311244\n",
      "F1 score at threshold 0.22 is 0.6628751974723539\n",
      "F1 score at threshold 0.23 is 0.6644680851063829\n",
      "F1 score at threshold 0.24 is 0.6655913978494624\n",
      "F1 score at threshold 0.25 is 0.6678950791242142\n",
      "F1 score at threshold 0.26 is 0.6695100612423446\n",
      "F1 score at threshold 0.27 is 0.6711587319120733\n",
      "F1 score at threshold 0.28 is 0.6723811644216855\n",
      "F1 score at threshold 0.29 is 0.6735565041563694\n",
      "F1 score at threshold 0.3 is 0.6736746919859841\n",
      "F1 score at threshold 0.31 is 0.6740369272851607\n",
      "F1 score at threshold 0.32 is 0.6757812500000001\n",
      "F1 score at threshold 0.33 is 0.6758668676794618\n",
      "F1 score at threshold 0.34 is 0.6762505843852267\n",
      "F1 score at threshold 0.35 is 0.6753858842936256\n",
      "F1 score at threshold 0.36 is 0.6749881122206371\n",
      "F1 score at threshold 0.37 is 0.6760158216468896\n",
      "F1 score at threshold 0.38 is 0.6764741348124925\n",
      "F1 score at threshold 0.39 is 0.6745935452560058\n",
      "F1 score at threshold 0.4 is 0.673264907135875\n",
      "F1 score at threshold 0.41 is 0.6726623136626833\n",
      "F1 score at threshold 0.42 is 0.6727996021879663\n",
      "F1 score at threshold 0.43 is 0.672012027060887\n",
      "F1 score at threshold 0.44 is 0.6709612226853606\n",
      "F1 score at threshold 0.45 is 0.6706571574121244\n",
      "F1 score at threshold 0.46 is 0.6698319004234571\n",
      "F1 score at threshold 0.47 is 0.6683040330920373\n",
      "F1 score at threshold 0.48 is 0.6665799062988028\n",
      "F1 score at threshold 0.49 is 0.6663174436877947\n",
      "F1 score at threshold 0.5 is 0.6651697265882974\n",
      "Best threshold:  0.38\n"
     ]
    }
   ],
   "source": [
    "thresholds = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    res = metrics.f1_score(val_y, (pred_val_y_3 > thresh).astype(int))\n",
    "    thresholds.append([thresh, res])\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "best_thresh = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = lstm_model_4(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 294s 237us/step - loss: 0.1124 - acc: 0.9556 - val_loss: 0.0996 - val_acc: 0.9582\n",
      "Train on 1240815 samples, validate on 65307 samples\n",
      "Epoch 1/1\n",
      "1240815/1240815 [==============================] - 291s 234us/step - loss: 0.0922 - acc: 0.9628 - val_loss: 0.0948 - val_acc: 0.9610\n"
     ]
    }
   ],
   "source": [
    "pred_val_y_4, pred_test_y_4 = train_pred(model_4, epochs=2) # GloVe only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score at threshold 0.1 is 0.6109706113194383\n",
      "F1 score at threshold 0.11 is 0.6186357556843515\n",
      "F1 score at threshold 0.12 is 0.6268412438625204\n",
      "F1 score at threshold 0.13 is 0.6336450328673271\n",
      "F1 score at threshold 0.14 is 0.6389150499152382\n",
      "F1 score at threshold 0.15 is 0.6445125454893699\n",
      "F1 score at threshold 0.16 is 0.6487012355287479\n",
      "F1 score at threshold 0.17 is 0.6539601027059055\n",
      "F1 score at threshold 0.18 is 0.6573230553608971\n",
      "F1 score at threshold 0.19 is 0.6603045685279187\n",
      "F1 score at threshold 0.2 is 0.6638525687223309\n",
      "F1 score at threshold 0.21 is 0.6629845769070446\n",
      "F1 score at threshold 0.22 is 0.6650470053871342\n",
      "F1 score at threshold 0.23 is 0.6669521464511294\n",
      "F1 score at threshold 0.24 is 0.6676786295131735\n",
      "F1 score at threshold 0.25 is 0.6687863172897708\n",
      "F1 score at threshold 0.26 is 0.6707344131351232\n",
      "F1 score at threshold 0.27 is 0.6733938782374705\n",
      "F1 score at threshold 0.28 is 0.6742973708068903\n",
      "F1 score at threshold 0.29 is 0.6768208886852954\n",
      "F1 score at threshold 0.3 is 0.6781502890173411\n",
      "F1 score at threshold 0.31 is 0.6753945061367622\n",
      "F1 score at threshold 0.32 is 0.67312234293812\n",
      "F1 score at threshold 0.33 is 0.6748744919913937\n",
      "F1 score at threshold 0.34 is 0.6738999397227246\n",
      "F1 score at threshold 0.35 is 0.6740506329113924\n",
      "F1 score at threshold 0.36 is 0.673795476892822\n",
      "F1 score at threshold 0.37 is 0.674510775328214\n",
      "F1 score at threshold 0.38 is 0.6725951903807615\n",
      "F1 score at threshold 0.39 is 0.6707178123813141\n",
      "F1 score at threshold 0.4 is 0.6684594698424894\n",
      "F1 score at threshold 0.41 is 0.6650290885585003\n",
      "F1 score at threshold 0.42 is 0.6607422895974908\n",
      "F1 score at threshold 0.43 is 0.656897689768977\n",
      "F1 score at threshold 0.44 is 0.6537846481876333\n",
      "F1 score at threshold 0.45 is 0.6538358008075371\n",
      "F1 score at threshold 0.46 is 0.6519727891156463\n",
      "F1 score at threshold 0.47 is 0.6487825010317788\n",
      "F1 score at threshold 0.48 is 0.645798553144129\n",
      "F1 score at threshold 0.49 is 0.6425059699395983\n",
      "F1 score at threshold 0.5 is 0.6382857953739182\n",
      "Best threshold:  0.3\n"
     ]
    }
   ],
   "source": [
    "thresholds = []\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    thresh = np.round(thresh, 2)\n",
    "    res = metrics.f1_score(val_y, (pred_val_y_4 > thresh).astype(int))\n",
    "    thresholds.append([thresh, res])\n",
    "    print(\"F1 score at threshold {0} is {1}\".format(thresh, res))\n",
    "    \n",
    "thresholds.sort(key=lambda x: x[1], reverse=True)\n",
    "best_thresh = thresholds[0][0]\n",
    "print(\"Best threshold: \", best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_test_y = (pred_test_y > best_thresh).astype(int)\n",
    "# test_df = pd.read_csv(\"../input/test.csv\", usecols=[\"qid\"])\n",
    "# out_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\n",
    "# out_df['prediction'] = pred_test_y\n",
    "# out_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
